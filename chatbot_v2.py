"""
Chatbot de AB Testing refactorizado con Superlinked
Versi√≥n modular siguiendo mejores pr√°cticas
"""

from superlinked.framework.dsl.executor.in_memory.in_memory_executor import InMemoryExecutor
from openai import OpenAI
from typing import Dict, List, Any
import sys
import traceback

# Imports de m√≥dulos locales
from config import settings
from index import create_ab_testing_index
from query import ABTestingQueryEngine
from data_processing import ABTestingDataProcessor
from analytics import ABTestingAnalytics
from intent_router import IntentRouter

class ABTestingChatbotV2:
    """Chatbot de AB Testing refactorizado con arquitectura modular"""
    
    def __init__(self):
        print("üöÄ Inicializando Chatbot de AB Testing v2.0...")
        
        # Configuraci√≥n
        self.settings = settings
        self.openai_client = OpenAI(api_key=settings.openai_api_key.get_secret_value())
        
        # Procesamiento de datos
        print("üìä Cargando y procesando datos...")
        self.data_processor = ABTestingDataProcessor()
        self.analytics = ABTestingAnalytics(self.data_processor.data)
        
        # Crear √≠ndice Superlinked
        print("üîç Creando √≠ndice vectorial Superlinked...")
        self.index, self.schema, self.spaces = create_ab_testing_index()
        
        # Configurar source y executor
        from superlinked.framework.dsl.source.in_memory_source import InMemorySource
        
        self.source = InMemorySource(self.schema)
        self.executor = InMemoryExecutor(sources=[self.source], indices=[self.index])
        self.app = self.executor.run()
        
        # Indexar documentos
        documents = self.data_processor.prepare_documents()
        if documents:
            self.source.put(documents)
        
        # Motor de consultas
        self.query_engine = ABTestingQueryEngine(self.index, self.schema, self.spaces, self.app)
        
        # Router de intents
        self.intent_router = IntentRouter(self.data_processor, self.settings)
        
        # Cache de an√°lisis
        self._ab_analysis_cache = None
        
        print("‚úÖ Chatbot inicializado correctamente!")
        self._print_data_summary()
    
    def _print_data_summary(self):
        """Imprime resumen de los datos cargados"""
        summary = self.data_processor.get_data_summary()
        print(f"""
üìà DATOS CARGADOS:
‚Ä¢ Total registros: {summary['total_records']}
‚Ä¢ Experimentos: {', '.join(summary['experiments'])}
‚Ä¢ Regiones: {', '.join(summary['regions'])}
‚Ä¢ Tipos de tienda: {', '.join(summary['store_types'])}
‚Ä¢ Total usuarios: {summary['total_users']:,}
‚Ä¢ Total conversiones: {summary['total_conversions']:,}
‚Ä¢ Revenue total: ${summary['total_revenue']:,.2f}
""")
    
    def get_ab_analysis(self) -> Dict[str, Any]:
        """Obtiene an√°lisis completo de AB Testing (con cache)"""
        if self._ab_analysis_cache is None:
            self._ab_analysis_cache = self.analytics.analyze_ab_test_results()
        return self._ab_analysis_cache
    
    def generate_response(self, user_query: str) -> str:
        """Genera respuesta usando OpenAI con contexto enriquecido"""
        try:
            # Usar el router de intents para consultas simples
            simple_response = self.intent_router.route_query(user_query)
            if simple_response:
                return simple_response
            
            # Extraer filtros autom√°ticamente
            filters = self.query_engine.extract_filters_from_query(user_query)
            
            # Detectar si es una consulta de performance (mayor/menor/top/mejor)
            performance_results = []
            if self._is_performance_query(user_query):
                performance_results = self._handle_performance_query(user_query, filters)
            
            # B√∫squeda sem√°ntica
            semantic_results = self.query_engine.semantic_search(
                user_query, 
                filters=filters,
                limit=self.settings.default_limit
            )
            
            # B√∫squeda por filtros si los hay
            filter_results = []
            if filters:
                filter_results = self.query_engine.filter_search(**filters)
            
            # Obtener an√°lisis completo
            ab_analysis = self.get_ab_analysis()
            
            # Crear contexto enriquecido
            context = self._build_context(user_query, semantic_results, filter_results, ab_analysis, performance_results)
            
            # Generar respuesta con OpenAI
            response = self.openai_client.chat.completions.create(
                model=self.settings.openai_model_id,
                messages=[
                    {
                        "role": "system", 
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user", 
                        "content": context
                    }
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            error_msg = f"Error generando respuesta: {str(e)}"
            print(f"‚ùå {error_msg}")
            traceback.print_exc()
            return f"Lo siento, ocurri√≥ un error al procesar tu consulta: {error_msg}"
    
    def _is_performance_query(self, query: str) -> bool:
        """Detecta si es una consulta de performance/ranking"""
        query_lower = query.lower()
        performance_keywords = [
            "mayor", "menor", "m√°ximo", "m√≠nimo", "mejor", "peor",
            "top", "ranking", "m√°s alto", "m√°s bajo", "highest", "lowest",
            "best", "worst", "m√°x", "m√≠n"
        ]
        return any(keyword in query_lower for keyword in performance_keywords)
    
    def _handle_performance_query(self, query: str, filters: Dict) -> List[Dict]:
        """Maneja consultas de performance espec√≠ficas"""
        query_lower = query.lower()
        
        # Determinar m√©trica y orden
        metric = 'conversion_rate'  # Default
        order = 'desc'  # Default para "mayor/mejor"
        
        if any(word in query_lower for word in ["revenue", "ingreso", "ganancia"]):
            metric = 'revenue'
        elif any(word in query_lower for word in ["usuario", "users", "tr√°fico"]):
            metric = 'usuarios'
        elif any(word in query_lower for word in ["conversion", "conversi√≥n"]):
            metric = 'conversion_rate'
        
        if any(word in query_lower for word in ["menor", "m√≠nimo", "peor", "lowest", "worst", "m√≠n"]):
            order = 'asc'
        
        # Obtener top performers
        try:
            return self.query_engine.get_top_performers(
                metric=metric, 
                order=order, 
                limit=5,
                filters=filters
            )
        except Exception as e:
            print(f"Error en performance query: {e}")
            return []
    
    def _build_context(self, query: str, semantic_results: List[Dict], 
                      filter_results: List[Dict], ab_analysis: Dict, 
                      performance_results: List[Dict] = None) -> str:
        """Construye contexto enriquecido para OpenAI"""
        
        context = f"""
CONSULTA DEL USUARIO: {query}

{ab_analysis['summary']}

AN√ÅLISIS POR SEGMENTOS:
"""
        
        # An√°lisis regional
        if ab_analysis['regional_analysis']:
            context += "\nüåç AN√ÅLISIS POR REGI√ìN:\n"
            for region, data in ab_analysis['regional_analysis'].items():
                context += f"‚Ä¢ {region}: Lift {data['lift']:+.2f}% (Control: {data['control_conversion_rate']:.2f}% ‚Üí Experimento: {data['experiment_conversion_rate']:.2f}%)\n"
        
        # An√°lisis por tipo de tienda
        if ab_analysis['store_type_analysis']:
            context += "\nüè™ AN√ÅLISIS POR TIPO DE TIENDA:\n"
            for store_type, data in ab_analysis['store_type_analysis'].items():
                context += f"‚Ä¢ {store_type}: Lift {data['lift']:+.2f}% (Control: {data['control_conversion_rate']:.2f}% ‚Üí Experimento: {data['experiment_conversion_rate']:.2f}%)\n"
        
        # Resultados de b√∫squeda sem√°ntica
        if semantic_results:
            context += f"\nüîç DATOS M√ÅS RELEVANTES (b√∫squeda sem√°ntica):\n"
            for i, result in enumerate(semantic_results[:3], 1):
                context += f"{i}. {result['description']} (Relevancia: {result['score']:.3f})\n"
        
        # Resultados de filtros
        if filter_results:
            context += f"\nüìã DATOS FILTRADOS:\n"
            for i, result in enumerate(filter_results[:3], 1):
                context += f"{i}. {result['description']}\n"
        
        # Resultados de performance (TOP/RANKING)
        if performance_results:
            context += f"\nüèÜ TOP PERFORMERS (ranking por m√©tricas):\n"
            for i, result in enumerate(performance_results, 1):
                context += f"{i}. Tienda ID: {result.get('tienda_id', 'N/A')} - "
                context += f"Experimento: {result.get('experimento', 'N/A')} - "
                context += f"Conversi√≥n: {result.get('conversion_rate', 0):.2f}% - "
                context += f"Revenue: ${result.get('revenue', 0):,.2f} - "
                context += f"Usuarios: {result.get('usuarios', 0):,}\n"
        
        context += f"\nResponde de manera clara y precisa bas√°ndote en estos datos."
        
        return context
    
    def _get_system_prompt(self) -> str:
        """Obtiene el prompt del sistema"""
        return """Eres un analista experto en AB Testing y estad√≠stica. 

ESTILO DE RESPUESTA:
- Respuestas CONCISAS y DIRECTAS
- Solo informaci√≥n relevante a la pregunta espec√≠fica
- Evita an√°lisis extensos no solicitados
- M√°ximo 3-4 oraciones para preguntas simples
- An√°lisis detallado solo cuando se solicite expl√≠citamente

FUNCIONES:
1. Responder preguntas espec√≠ficas sobre datos de AB Testing
2. Interpretar m√©tricas (conversion rate, revenue, lifts)
3. Explicar significancia estad√≠stica cuando sea relevante
4. Proporcionar insights cuando se soliciten

REGLAS:
- Basa respuestas solo en datos proporcionados
- S√© espec√≠fico con n√∫meros y porcentajes
- Si la pregunta es simple (conteo, datos b√°sicos), responde directamente
- Solo proporciona an√°lisis extenso si se solicita expl√≠citamente"""
    
    def run_console_chat(self):
        """Ejecuta el chatbot en modo consola interactivo"""
        print("\n" + "="*60)
        print("ü§ñ CHATBOT AB TESTING v2.0 - MODO INTERACTIVO")
        print("="*60)
        print("üí° Ejemplos de preguntas:")
        print("   ‚Ä¢ ¬øCu√°l fue el lift en conversiones del experimento?")
        print("   ‚Ä¢ ¬øC√≥mo se comportaron las tiendas Mall vs Street?")
        print("   ‚Ä¢ ¬øHay diferencias significativas por regi√≥n?")
        print("   ‚Ä¢ ¬øQu√© regi√≥n tuvo mejor performance?")
        print("\nüìù Escribe 'salir' para terminar")
        print("-"*60)
        
        while True:
            try:
                user_input = input("\nüìä Tu pregunta: ").strip()
                
                if user_input.lower() in ['salir', 'exit', 'quit', 'q']:
                    print("\nüëã ¬°Hasta luego! Gracias por usar el chatbot.")
                    break
                
                if not user_input:
                    print("‚ö†Ô∏è  Por favor, escribe una pregunta.")
                    continue
                
                print("\nüîÑ Analizando...")
                response = self.generate_response(user_input)
                print(f"\nü§ñ Respuesta:\n{response}")
                print("\n" + "-"*60)
                
            except KeyboardInterrupt:
                print("\n\nüëã Chat interrumpido. ¬°Hasta luego!")
                break
            except Exception as e:
                print(f"\n‚ùå Error inesperado: {str(e)}")
                continue

def main():
    """Funci√≥n principal"""
    try:
        chatbot = ABTestingChatbotV2()
        chatbot.run_console_chat()
    except Exception as e:
        print(f"‚ùå Error fatal al inicializar chatbot: {str(e)}")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()