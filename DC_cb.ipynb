{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f1d76",
   "metadata": {},
   "outputs": [],
   "source": "# Comparaci√≥n: Chat Completions vs Responses API\n# Ejemplo pr√°ctico de migraci√≥n para mantener historial de conversaci√≥n\n\nimport os\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\n\n# Cargar variables de entorno\nload_dotenv()\n\n# Configurar cliente con token desde .env\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# =============================================================================\n# M√âTODO TRADICIONAL (Chat Completions) - Gesti√≥n manual del historial\n# =============================================================================\n\nprint(\"=== M√âTODO TRADICIONAL (Chat Completions) ===\")\nmessages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor that speaks concisely.\"}]\nuser_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n\n# Loop over the user questions\nfor q in user_msgs:\n    print(\"User: \", q)\n    \n    # Create a dictionary for the user message from q and append to messages\n    user_dict = {\"role\": 'user', \"content\": q}\n    messages.append(user_dict)\n    \n    # Create the API request\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=messages,\n        max_completion_tokens=100\n    )\n    \n    # Append the assistant's message to messages\n    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n    messages.append(assistant_dict)\n    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")\n\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cvr4hh8p4pe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NUEVO M√âTODO (Responses API) - Gesti√≥n autom√°tica del historial\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== NUEVO M√âTODO (Responses API) ===\")\n",
    "\n",
    "# Configurar prompt inicial del sistema\n",
    "system_prompt = \"You are a helpful math tutor that speaks concisely.\"\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "# Variable para almacenar el ID de la conversaci√≥n\n",
    "conversation_id = None\n",
    "\n",
    "# Loop over the user questions\n",
    "for i, q in enumerate(user_msgs):\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    if i == 0:\n",
    "        # Primera consulta: incluir sistema + usuario\n",
    "        input_text = f\"System: {system_prompt}\\n\\nUser: {q}\"\n",
    "        \n",
    "        # Crear primera respuesta con store=True para mantener estado\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=input_text,\n",
    "            store=True  # Habilita gesti√≥n autom√°tica de estado\n",
    "        )\n",
    "        \n",
    "        # Guardar ID para continuar conversaci√≥n\n",
    "        conversation_id = response.id\n",
    "        \n",
    "    else:\n",
    "        # Consultas siguientes: usar previous_response_id para mantener historial\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=q,\n",
    "            previous_response_id=conversation_id,\n",
    "            store=True\n",
    "        )\n",
    "        \n",
    "        # Actualizar conversation_id para pr√≥xima interacci√≥n\n",
    "        conversation_id = response.id\n",
    "    \n",
    "    print(\"Assistant: \", response.content, \"\\n\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2j413zrcqp",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# EJEMPLO PR√ÅCTICO: Aplicando Responses API al Chatbot AB Testing\n# =============================================================================\n\nprint(\"\\n=== CHATBOT AB TESTING CON RESPONSES API ===\")\n\nclass ABTestingChatbotResponses:\n    \"\"\"Chatbot AB Testing usando la nueva API Responses\"\"\"\n    \n    def __init__(self):\n        # Usar el mismo cliente ya configurado con .env\n        self.client = client\n        self.conversations = {}  # Almacenar IDs por sesi√≥n\n        \n    def chat(self, query: str, session_id: str = \"default\"):\n        \"\"\"Env√≠a una consulta y mantiene historial autom√°ticamente\"\"\"\n        \n        # Prompt del sistema para AB Testing\n        system_prompt = \"\"\"Eres un analista experto en AB Testing. \n        Responde preguntas sobre datos de experimentos, m√©tricas de conversi√≥n, \n        y an√°lisis estad√≠stico de manera concisa y precisa.\"\"\"\n        \n        # Verificar si existe conversaci√≥n previa\n        previous_id = self.conversations.get(session_id)\n        \n        if previous_id:\n            # Continuar conversaci√≥n existente\n            response = self.client.responses.create(\n                model=\"gpt-4o-mini\",\n                input=query,\n                previous_response_id=previous_id,\n                store=True\n            )\n        else:\n            # Iniciar nueva conversaci√≥n\n            input_text = f\"System: {system_prompt}\\n\\nUser: {query}\"\n            response = self.client.responses.create(\n                model=\"gpt-4o-mini\", \n                input=input_text,\n                store=True\n            )\n        \n        # Actualizar ID de conversaci√≥n\n        self.conversations[session_id] = response.id\n        \n        return response.content\n    \n    def reset_session(self, session_id: str = \"default\"):\n        \"\"\"Reinicia una sesi√≥n de conversaci√≥n\"\"\"\n        if session_id in self.conversations:\n            del self.conversations[session_id]\n            print(f\"Sesi√≥n '{session_id}' reiniciada.\")\n    \n    def get_conversation_history(self, session_id: str = \"default\"):\n        \"\"\"Obtiene el historial completo (funcionalidad de Responses API)\"\"\"\n        conversation_id = self.conversations.get(session_id)\n        if conversation_id:\n            try:\n                # Obtener respuesta completa con historial\n                response = self.client.responses.retrieve(conversation_id)\n                return response.content\n            except Exception as e:\n                return f\"Error obteniendo historial: {e}\"\n        return \"No hay conversaci√≥n activa.\"\n\n# Ejemplo de uso\nchatbot = ABTestingChatbotResponses()\n\n# Simulaci√≥n de conversaci√≥n con historial autom√°tico\nqueries = [\n    \"¬øQu√© es un AB Test?\",\n    \"¬øC√≥mo se calcula el lift?\", \n    \"Dame un ejemplo con n√∫meros espec√≠ficos\"\n]\n\nprint(\"Conversaci√≥n con historial autom√°tico:\")\nfor i, query in enumerate(queries, 1):\n    print(f\"\\n[{i}] Usuario: {query}\")\n    response = chatbot.chat(query, session_id=\"demo\")\n    print(f\"[{i}] Bot: {response}\")\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "id": "6e8cb81u5jo",
   "metadata": {},
   "source": [
    "## Ventajas de la Migraci√≥n a Responses API\n",
    "\n",
    "### ‚úÖ **Antes (Chat Completions)**\n",
    "- ‚ùå Gesti√≥n manual del array `messages`\n",
    "- ‚ùå C√≥digo m√°s complejo para mantener historial\n",
    "- ‚ùå Riesgo de perder contexto por errores de c√≥digo\n",
    "- ‚ùå Manejo manual de l√≠mites de tokens\n",
    "\n",
    "### ‚úÖ **Despu√©s (Responses API)**\n",
    "- ‚úÖ Gesti√≥n autom√°tica del historial con `previous_response_id`\n",
    "- ‚úÖ C√≥digo m√°s limpio y mantenible\n",
    "- ‚úÖ Estado persistente manejado por OpenAI\n",
    "- ‚úÖ Optimizaci√≥n autom√°tica de tokens\n",
    "- ‚úÖ Soporte nativo para herramientas avanzadas\n",
    "\n",
    "### üîë **Puntos Clave para la Migraci√≥n**\n",
    "\n",
    "1. **`store=True`**: Habilita la gesti√≥n autom√°tica de estado\n",
    "2. **`previous_response_id`**: Contin√∫a conversaciones existentes\n",
    "3. **Menos c√≥digo**: No necesitas gestionar el array de mensajes\n",
    "4. **Mejor rendimiento**: OpenAI optimiza autom√°ticamente el contexto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chatbot2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}