{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d23f1d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MÉTODO TRADICIONAL (Chat Completions) ===\n",
      "User:  ¿Cómo te llamas?\n",
      "Assistant:  Soy un asistente virtual y no tengo un nombre propio, pero puedes llamarme simplemente \"asistente\". ¿En qué puedo ayudarte hoy? \n",
      "\n",
      "User:  ¿Cuál fue mi anterior pregunta?\n",
      "Assistant:  Tu anterior pregunta fue \"¿Cómo te llamas?\" ¿Hay algo más en lo que te gustaría profundizar? \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comparación: Chat Completions vs Responses API\n",
    "# Ejemplo práctico de migración para mantener historial de conversación\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar cliente con token desde .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# =============================================================================\n",
    "# MÉTODO TRADICIONAL (Chat Completions) - Gestión manual del historial\n",
    "# =============================================================================\n",
    "print(\"=== MÉTODO TRADICIONAL (Chat Completions) ===\")\n",
    "messages = [{\"role\": \"system\", \"content\": \"Eres un instructor conversacional.\"}]\n",
    "user_msgs = [\"¿Cómo te llamas?\", \"¿Cuál fue mi anterior pregunta?\"]\n",
    "\n",
    "# Loop over the user questions\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": 'user', \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_completion_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Append the assistant's message to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cvr4hh8p4pe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NUEVO MÉTODO (Responses API) ===\n",
      "User:  ¿Cómo te llamas?\n",
      "Assistant:  Soy un modelo de inteligencia artificial, así que no tengo un nombre propio. Pero puedes llamarme asistente. ¿En qué puedo ayudarte hoy? \n",
      "\n",
      "User:  ¿Cuál fue mi anterior pregunta?\n",
      "Assistant:  Tu anterior pregunta fue: \"¿Cómo te llamas?\" ¿Hay algo más en lo que te gustaría conversar? \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NUEVO MÉTODO (Responses API) - Gestión automática del historial\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== NUEVO MÉTODO (Responses API) ===\")\n",
    "\n",
    "# Configurar prompt inicial del sistema\n",
    "system_prompt = \"Eres un instructor conversacional.\"\n",
    "user_msgs = [\"¿Cómo te llamas?\", \"¿Cuál fue mi anterior pregunta?\"]\n",
    "\n",
    "# Variable para almacenar el ID de la conversación\n",
    "conversation_id = None\n",
    "\n",
    "# Loop over the user questions\n",
    "for i, q in enumerate(user_msgs):\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    if i == 0:\n",
    "        # Primera consulta: incluir sistema + usuario\n",
    "        input_text = f\"System: {system_prompt}\\n\\nUser: {q}\"\n",
    "        \n",
    "        # Crear primera respuesta con store=True para mantener estado\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=input_text,\n",
    "            store=True  # Habilita gestión automática de estado\n",
    "        )\n",
    "        \n",
    "        # Guardar ID para continuar conversación\n",
    "        conversation_id = response.id\n",
    "        \n",
    "    else:\n",
    "        # Consultas siguientes: usar previous_response_id para mantener historial\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=q,\n",
    "            previous_response_id=conversation_id,\n",
    "            store=True\n",
    "        )\n",
    "        \n",
    "        # Actualizar conversation_id para próxima interacción\n",
    "        conversation_id = response.id\n",
    "    \n",
    "    print(\"Assistant: \", response.output[0].content[0].text, \"\\n\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba59e91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pi (π) is a mathematical constant representing the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14 and is an irrational number, meaning it has an infinite number of non-repeating decimal places. Pi is used in various formulas involving circles and is essential in geometry and trigonometry.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2j413zrcqp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHATBOT AB TESTING CON RESPONSES API ===\n",
      "Conversación con historial automático:\n",
      "\n",
      "[1] Usuario: ¿Qué es un AB Test?\n",
      "[1] Bot: Un AB Test es un experimento en el que se comparan dos versiones de una variable (A y B) para determinar cuál es más efectiva en lograr un objetivo específico, como aumentar la tasa de conversión o mejorar la interacción del usuario. Se selecciona aleatoriamente a los usuarios para que vean una de las dos versiones, y se analizan las métricas relevantes para evaluar el rendimiento de cada versión. Los resultados ayudan a tomar decisiones informadas sobre cambios en productos o estrategias.\n",
      "\n",
      "[2] Usuario: ¿Cómo se calcula el lift?\n",
      "[2] Bot: El lift (aumento) se calcula comparando la tasa de conversión de la variante B con la tasa de conversión de la variante A. La fórmula es la siguiente:\n",
      "\n",
      "\\[\n",
      "\\text{Lift} = \\left( \\frac{\\text{Tasa de Conversión B} - \\text{Tasa de Conversión A}}{\\text{Tasa de Conversión A}} \\right) \\times 100\n",
      "\\]\n",
      "\n",
      "Donde:\n",
      "\n",
      "- **Tasa de Conversión A** = (Número de conversiones en A) / (Número total de visitantes en A)\n",
      "- **Tasa de Conversión B** = (Número de conversiones en B) / (Número total de visitantes en B)\n",
      "\n",
      "El resultado se expresa como un porcentaje que indica el aumento en la tasa de conversión de la variante B respecto a la A.\n",
      "\n",
      "[3] Usuario: Dame un ejemplo con números específicos\n",
      "[3] Bot: Claro, aquí tienes un ejemplo con números específicos:\n",
      "\n",
      "Supongamos que realizas un AB Test para comparar dos versiones de una página de aterrizaje:\n",
      "\n",
      "- **Versión A** (control):\n",
      "  - Número de visitantes: 1000\n",
      "  - Número de conversiones: 50\n",
      "\n",
      "- **Versión B** (variante):\n",
      "  - Número de visitantes: 1000\n",
      "  - Número de conversiones: 70\n",
      "\n",
      "1. **Calcula la tasa de conversión**:\n",
      "\n",
      "   - Tasa de Conversión A:\n",
      "   \\[\n",
      "   \\text{Tasa de Conversión A} = \\frac{50}{1000} = 0.05 \\text{ o } 5\\%\n",
      "   \\]\n",
      "\n",
      "   - Tasa de Conversión B:\n",
      "   \\[\n",
      "   \\text{Tasa de Conversión B} = \\frac{70}{1000} = 0.07 \\text{ o } 7\\%\n",
      "   \\]\n",
      "\n",
      "2. **Calcula el lift**:\n",
      "\n",
      "\\[\n",
      "\\text{Lift} = \\left( \\frac{0.07 - 0.05}{0.05} \\right) \\times 100\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "\\text{Lift} = \\left( \\frac{0.02}{0.05} \\right) \\times 100 = 40\\%\n",
      "\\]\n",
      "\n",
      "En este ejemplo, el lift de la variante B respecto a la versión A es del **40%**, lo que indica que B es más efectiva en términos de conversión.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EJEMPLO PRÁCTICO: Aplicando Responses API al Chatbot AB Testing\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== CHATBOT AB TESTING CON RESPONSES API ===\")\n",
    "\n",
    "class ABTestingChatbotResponses:\n",
    "    \"\"\"Chatbot AB Testing usando la nueva API Responses\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Usar el mismo cliente ya configurado con .env\n",
    "        self.client = client\n",
    "        self.conversations = {}  # Almacenar IDs por sesión\n",
    "        \n",
    "    def chat(self, query: str, session_id: str = \"default\"):\n",
    "        \"\"\"Envía una consulta y mantiene historial automáticamente\"\"\"\n",
    "        \n",
    "        # Prompt del sistema para AB Testing\n",
    "        system_prompt = \"\"\"Eres un analista experto en AB Testing. \n",
    "        Responde preguntas sobre datos de experimentos, métricas de conversión, \n",
    "        y análisis estadístico de manera concisa y precisa.\"\"\"\n",
    "        \n",
    "        # Verificar si existe conversación previa\n",
    "        previous_id = self.conversations.get(session_id)\n",
    "        \n",
    "        if previous_id:\n",
    "            # Continuar conversación existente\n",
    "            response = self.client.responses.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                input=query,\n",
    "                previous_response_id=previous_id,\n",
    "                store=True\n",
    "            )\n",
    "        else:\n",
    "            # Iniciar nueva conversación\n",
    "            input_text = f\"System: {system_prompt}\\n\\nUser: {query}\"\n",
    "            response = self.client.responses.create(\n",
    "                model=\"gpt-4o-mini\", \n",
    "                input=input_text,\n",
    "                store=True\n",
    "            )\n",
    "        \n",
    "        # Actualizar ID de conversación\n",
    "        self.conversations[session_id] = response.id\n",
    "        \n",
    "        return response.output[0].content[0].text\n",
    "    \n",
    "    def reset_session(self, session_id: str = \"default\"):\n",
    "        \"\"\"Reinicia una sesión de conversación\"\"\"\n",
    "        if session_id in self.conversations:\n",
    "            del self.conversations[session_id]\n",
    "            print(f\"Sesión '{session_id}' reiniciada.\")\n",
    "    \n",
    "    def get_conversation_history(self, session_id: str = \"default\"):\n",
    "        \"\"\"Obtiene el historial completo (funcionalidad de Responses API)\"\"\"\n",
    "        conversation_id = self.conversations.get(session_id)\n",
    "        if conversation_id:\n",
    "            try:\n",
    "                # Obtener respuesta completa con historial\n",
    "                response = self.client.responses.retrieve(conversation_id)\n",
    "                return response.output[0].content[0].text\n",
    "            except Exception as e:\n",
    "                return f\"Error obteniendo historial: {e}\"\n",
    "        return \"No hay conversación activa.\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "chatbot = ABTestingChatbotResponses()\n",
    "\n",
    "# Simulación de conversación con historial automático\n",
    "queries = [\n",
    "    \"¿Qué es un AB Test?\",\n",
    "    \"¿Cómo se calcula el lift?\", \n",
    "    \"Dame un ejemplo con números específicos\"\n",
    "]\n",
    "\n",
    "print(\"Conversación con historial automático:\")\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\n[{i}] Usuario: {query}\")\n",
    "    response = chatbot.chat(query, session_id=\"demo\")\n",
    "    print(f\"[{i}] Bot: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cb81u5jo",
   "metadata": {},
   "source": [
    "## Ventajas de la Migración a Responses API\n",
    "\n",
    "### ✅ **Antes (Chat Completions)**\n",
    "- ❌ Gestión manual del array `messages`\n",
    "- ❌ Código más complejo para mantener historial\n",
    "- ❌ Riesgo de perder contexto por errores de código\n",
    "- ❌ Manejo manual de límites de tokens\n",
    "\n",
    "### ✅ **Después (Responses API)**\n",
    "- ✅ Gestión automática del historial con `previous_response_id`\n",
    "- ✅ Código más limpio y mantenible\n",
    "- ✅ Estado persistente manejado por OpenAI\n",
    "- ✅ Optimización automática de tokens\n",
    "- ✅ Soporte nativo para herramientas avanzadas\n",
    "\n",
    "### 🔑 **Puntos Clave para la Migración**\n",
    "\n",
    "1. **`store=True`**: Habilita la gestión automática de estado\n",
    "2. **`previous_response_id`**: Continúa conversaciones existentes\n",
    "3. **Menos código**: No necesitas gestionar el array de mensajes\n",
    "4. **Mejor rendimiento**: OpenAI optimiza automáticamente el contexto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chatbot2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
