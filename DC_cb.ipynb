{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d23f1d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== M√âTODO TRADICIONAL (Chat Completions) ===\n",
      "User:  ¬øC√≥mo te llamas?\n",
      "Assistant:  Soy un asistente virtual y no tengo un nombre propio, pero puedes llamarme simplemente \"asistente\". ¬øEn qu√© puedo ayudarte hoy? \n",
      "\n",
      "User:  ¬øCu√°l fue mi anterior pregunta?\n",
      "Assistant:  Tu anterior pregunta fue \"¬øC√≥mo te llamas?\" ¬øHay algo m√°s en lo que te gustar√≠a profundizar? \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comparaci√≥n: Chat Completions vs Responses API\n",
    "# Ejemplo pr√°ctico de migraci√≥n para mantener historial de conversaci√≥n\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar cliente con token desde .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# =============================================================================\n",
    "# M√âTODO TRADICIONAL (Chat Completions) - Gesti√≥n manual del historial\n",
    "# =============================================================================\n",
    "print(\"=== M√âTODO TRADICIONAL (Chat Completions) ===\")\n",
    "messages = [{\"role\": \"system\", \"content\": \"Eres un instructor conversacional.\"}]\n",
    "user_msgs = [\"¬øC√≥mo te llamas?\", \"¬øCu√°l fue mi anterior pregunta?\"]\n",
    "\n",
    "# Loop over the user questions\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": 'user', \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_completion_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Append the assistant's message to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cvr4hh8p4pe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NUEVO M√âTODO (Responses API) ===\n",
      "User:  ¬øC√≥mo te llamas?\n",
      "Assistant:  Soy un modelo de inteligencia artificial, as√≠ que no tengo un nombre propio. Pero puedes llamarme asistente. ¬øEn qu√© puedo ayudarte hoy? \n",
      "\n",
      "User:  ¬øCu√°l fue mi anterior pregunta?\n",
      "Assistant:  Tu anterior pregunta fue: \"¬øC√≥mo te llamas?\" ¬øHay algo m√°s en lo que te gustar√≠a conversar? \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NUEVO M√âTODO (Responses API) - Gesti√≥n autom√°tica del historial\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== NUEVO M√âTODO (Responses API) ===\")\n",
    "\n",
    "# Configurar prompt inicial del sistema\n",
    "system_prompt = \"Eres un instructor conversacional.\"\n",
    "user_msgs = [\"¬øC√≥mo te llamas?\", \"¬øCu√°l fue mi anterior pregunta?\"]\n",
    "\n",
    "# Variable para almacenar el ID de la conversaci√≥n\n",
    "conversation_id = None\n",
    "\n",
    "# Loop over the user questions\n",
    "for i, q in enumerate(user_msgs):\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    if i == 0:\n",
    "        # Primera consulta: incluir sistema + usuario\n",
    "        input_text = f\"System: {system_prompt}\\n\\nUser: {q}\"\n",
    "        \n",
    "        # Crear primera respuesta con store=True para mantener estado\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=input_text,\n",
    "            store=True  # Habilita gesti√≥n autom√°tica de estado\n",
    "        )\n",
    "        \n",
    "        # Guardar ID para continuar conversaci√≥n\n",
    "        conversation_id = response.id\n",
    "        \n",
    "    else:\n",
    "        # Consultas siguientes: usar previous_response_id para mantener historial\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=q,\n",
    "            previous_response_id=conversation_id,\n",
    "            store=True\n",
    "        )\n",
    "        \n",
    "        # Actualizar conversation_id para pr√≥xima interacci√≥n\n",
    "        conversation_id = response.id\n",
    "    \n",
    "    print(\"Assistant: \", response.output[0].content[0].text, \"\\n\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba59e91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pi (œÄ) is a mathematical constant representing the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14 and is an irrational number, meaning it has an infinite number of non-repeating decimal places. Pi is used in various formulas involving circles and is essential in geometry and trigonometry.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2j413zrcqp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHATBOT AB TESTING CON RESPONSES API ===\n",
      "Conversaci√≥n con historial autom√°tico:\n",
      "\n",
      "[1] Usuario: ¬øQu√© es un AB Test?\n",
      "[1] Bot: Un AB Test es un experimento en el que se comparan dos versiones de una variable (A y B) para determinar cu√°l es m√°s efectiva en lograr un objetivo espec√≠fico, como aumentar la tasa de conversi√≥n o mejorar la interacci√≥n del usuario. Se selecciona aleatoriamente a los usuarios para que vean una de las dos versiones, y se analizan las m√©tricas relevantes para evaluar el rendimiento de cada versi√≥n. Los resultados ayudan a tomar decisiones informadas sobre cambios en productos o estrategias.\n",
      "\n",
      "[2] Usuario: ¬øC√≥mo se calcula el lift?\n",
      "[2] Bot: El lift (aumento) se calcula comparando la tasa de conversi√≥n de la variante B con la tasa de conversi√≥n de la variante A. La f√≥rmula es la siguiente:\n",
      "\n",
      "\\[\n",
      "\\text{Lift} = \\left( \\frac{\\text{Tasa de Conversi√≥n B} - \\text{Tasa de Conversi√≥n A}}{\\text{Tasa de Conversi√≥n A}} \\right) \\times 100\n",
      "\\]\n",
      "\n",
      "Donde:\n",
      "\n",
      "- **Tasa de Conversi√≥n A** = (N√∫mero de conversiones en A) / (N√∫mero total de visitantes en A)\n",
      "- **Tasa de Conversi√≥n B** = (N√∫mero de conversiones en B) / (N√∫mero total de visitantes en B)\n",
      "\n",
      "El resultado se expresa como un porcentaje que indica el aumento en la tasa de conversi√≥n de la variante B respecto a la A.\n",
      "\n",
      "[3] Usuario: Dame un ejemplo con n√∫meros espec√≠ficos\n",
      "[3] Bot: Claro, aqu√≠ tienes un ejemplo con n√∫meros espec√≠ficos:\n",
      "\n",
      "Supongamos que realizas un AB Test para comparar dos versiones de una p√°gina de aterrizaje:\n",
      "\n",
      "- **Versi√≥n A** (control):\n",
      "  - N√∫mero de visitantes: 1000\n",
      "  - N√∫mero de conversiones: 50\n",
      "\n",
      "- **Versi√≥n B** (variante):\n",
      "  - N√∫mero de visitantes: 1000\n",
      "  - N√∫mero de conversiones: 70\n",
      "\n",
      "1. **Calcula la tasa de conversi√≥n**:\n",
      "\n",
      "   - Tasa de Conversi√≥n A:\n",
      "   \\[\n",
      "   \\text{Tasa de Conversi√≥n A} = \\frac{50}{1000} = 0.05 \\text{ o } 5\\%\n",
      "   \\]\n",
      "\n",
      "   - Tasa de Conversi√≥n B:\n",
      "   \\[\n",
      "   \\text{Tasa de Conversi√≥n B} = \\frac{70}{1000} = 0.07 \\text{ o } 7\\%\n",
      "   \\]\n",
      "\n",
      "2. **Calcula el lift**:\n",
      "\n",
      "\\[\n",
      "\\text{Lift} = \\left( \\frac{0.07 - 0.05}{0.05} \\right) \\times 100\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "\\text{Lift} = \\left( \\frac{0.02}{0.05} \\right) \\times 100 = 40\\%\n",
      "\\]\n",
      "\n",
      "En este ejemplo, el lift de la variante B respecto a la versi√≥n A es del **40%**, lo que indica que B es m√°s efectiva en t√©rminos de conversi√≥n.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EJEMPLO PR√ÅCTICO: Aplicando Responses API al Chatbot AB Testing\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n=== CHATBOT AB TESTING CON RESPONSES API ===\")\n",
    "\n",
    "class ABTestingChatbotResponses:\n",
    "    \"\"\"Chatbot AB Testing usando la nueva API Responses\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Usar el mismo cliente ya configurado con .env\n",
    "        self.client = client\n",
    "        self.conversations = {}  # Almacenar IDs por sesi√≥n\n",
    "        \n",
    "    def chat(self, query: str, session_id: str = \"default\"):\n",
    "        \"\"\"Env√≠a una consulta y mantiene historial autom√°ticamente\"\"\"\n",
    "        \n",
    "        # Prompt del sistema para AB Testing\n",
    "        system_prompt = \"\"\"Eres un analista experto en AB Testing. \n",
    "        Responde preguntas sobre datos de experimentos, m√©tricas de conversi√≥n, \n",
    "        y an√°lisis estad√≠stico de manera concisa y precisa.\"\"\"\n",
    "        \n",
    "        # Verificar si existe conversaci√≥n previa\n",
    "        previous_id = self.conversations.get(session_id)\n",
    "        \n",
    "        if previous_id:\n",
    "            # Continuar conversaci√≥n existente\n",
    "            response = self.client.responses.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                input=query,\n",
    "                previous_response_id=previous_id,\n",
    "                store=True\n",
    "            )\n",
    "        else:\n",
    "            # Iniciar nueva conversaci√≥n\n",
    "            input_text = f\"System: {system_prompt}\\n\\nUser: {query}\"\n",
    "            response = self.client.responses.create(\n",
    "                model=\"gpt-4o-mini\", \n",
    "                input=input_text,\n",
    "                store=True\n",
    "            )\n",
    "        \n",
    "        # Actualizar ID de conversaci√≥n\n",
    "        self.conversations[session_id] = response.id\n",
    "        \n",
    "        return response.output[0].content[0].text\n",
    "    \n",
    "    def reset_session(self, session_id: str = \"default\"):\n",
    "        \"\"\"Reinicia una sesi√≥n de conversaci√≥n\"\"\"\n",
    "        if session_id in self.conversations:\n",
    "            del self.conversations[session_id]\n",
    "            print(f\"Sesi√≥n '{session_id}' reiniciada.\")\n",
    "    \n",
    "    def get_conversation_history(self, session_id: str = \"default\"):\n",
    "        \"\"\"Obtiene el historial completo (funcionalidad de Responses API)\"\"\"\n",
    "        conversation_id = self.conversations.get(session_id)\n",
    "        if conversation_id:\n",
    "            try:\n",
    "                # Obtener respuesta completa con historial\n",
    "                response = self.client.responses.retrieve(conversation_id)\n",
    "                return response.output[0].content[0].text\n",
    "            except Exception as e:\n",
    "                return f\"Error obteniendo historial: {e}\"\n",
    "        return \"No hay conversaci√≥n activa.\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "chatbot = ABTestingChatbotResponses()\n",
    "\n",
    "# Simulaci√≥n de conversaci√≥n con historial autom√°tico\n",
    "queries = [\n",
    "    \"¬øQu√© es un AB Test?\",\n",
    "    \"¬øC√≥mo se calcula el lift?\", \n",
    "    \"Dame un ejemplo con n√∫meros espec√≠ficos\"\n",
    "]\n",
    "\n",
    "print(\"Conversaci√≥n con historial autom√°tico:\")\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\n[{i}] Usuario: {query}\")\n",
    "    response = chatbot.chat(query, session_id=\"demo\")\n",
    "    print(f\"[{i}] Bot: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cb81u5jo",
   "metadata": {},
   "source": [
    "## Ventajas de la Migraci√≥n a Responses API\n",
    "\n",
    "### ‚úÖ **Antes (Chat Completions)**\n",
    "- ‚ùå Gesti√≥n manual del array `messages`\n",
    "- ‚ùå C√≥digo m√°s complejo para mantener historial\n",
    "- ‚ùå Riesgo de perder contexto por errores de c√≥digo\n",
    "- ‚ùå Manejo manual de l√≠mites de tokens\n",
    "\n",
    "### ‚úÖ **Despu√©s (Responses API)**\n",
    "- ‚úÖ Gesti√≥n autom√°tica del historial con `previous_response_id`\n",
    "- ‚úÖ C√≥digo m√°s limpio y mantenible\n",
    "- ‚úÖ Estado persistente manejado por OpenAI\n",
    "- ‚úÖ Optimizaci√≥n autom√°tica de tokens\n",
    "- ‚úÖ Soporte nativo para herramientas avanzadas\n",
    "\n",
    "### üîë **Puntos Clave para la Migraci√≥n**\n",
    "\n",
    "1. **`store=True`**: Habilita la gesti√≥n autom√°tica de estado\n",
    "2. **`previous_response_id`**: Contin√∫a conversaciones existentes\n",
    "3. **Menos c√≥digo**: No necesitas gestionar el array de mensajes\n",
    "4. **Mejor rendimiento**: OpenAI optimiza autom√°ticamente el contexto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chatbot2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
